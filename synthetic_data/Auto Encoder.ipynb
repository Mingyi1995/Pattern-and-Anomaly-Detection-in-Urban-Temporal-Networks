{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemingyi/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'matrix']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#add necessary libraries\n",
    "import networkx as nx #library supporting networks\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy import optimize\n",
    "#make sure plots are embedded into the notebook\n",
    "%pylab inline \n",
    "import statsmodels.formula.api as smf\n",
    "#import shapefile as shp\n",
    "#from shapely.geometry.polygon import Polygon\n",
    "from descartes import PolygonPatch\n",
    "import os\n",
    "from networkx.algorithms import community\n",
    "from sklearn.mixture import GaussianMixture \n",
    "\n",
    "# Import required libraries\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Dropout\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import set_random_seed\n",
    "from keras import backend as K\n",
    "import datetime\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordWritingPath = '/Users/hemingyi/Documents/capstone/'\n",
    "TransportationDataPath = '/Users/hemingyi/Documents/capstone/transportation/'\n",
    "EventDataPath = '/Users/hemingyi/Documents/capstone/event data/new/'\n",
    "comboPath = '/Users/hemingyi/Documents/capstone/combo/'\n",
    "# dataFile = TransportationDataPath+city+'EdgeYearwiseAggregated.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTransDF(TransportationDataPath,city):\n",
    "    df = pd.read_csv(TransportationDataPath+city+'EdgeDatewiseAggregated.csv')\n",
    "    return df\n",
    "def makeGraphfromDf(df):\n",
    "    G=nx.DiGraph()\n",
    "    nx.set_edge_attributes(G,'weight', 0)\n",
    "    for k in df.index:\n",
    "        G.add_edge(df['start_id'][k],df['end_id'][k],weight=df['amount'][k])\n",
    "#     nx.write_edgelist(G, comboPath+'temp/%s.net'%city)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='amount', index=['date'],\n",
    "                    columns=['start_id','end_id'], aggfunc=np.sum, fill_value=0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyDetection(y,pval = 0.2,iterN=20):\n",
    "    #index of regular (non-outlier points)\n",
    "    #rind=y[:,0]>-10 \n",
    "    rind = np.array(range(y.shape[0]))\n",
    "    \n",
    "    #clustering model\n",
    "    gm=GaussianMixture(n_components=3,n_init=100,max_iter=1000,random_state=0) \n",
    "    for i in range(iterN): #iterate\n",
    "        print('Iteration {}'.format(i+1))  \n",
    "        clustering=gm.fit(y[rind,:]) #fit EM clustering model excluding outliers\n",
    "        l=clustering.score_samples(y) #estimate likelihood for each point\n",
    "        Lthres=sorted(l)[int(len(l)*pval)] #anomaly threshold\n",
    "        rind0=0+rind\n",
    "        rind=l>Lthres #non-anomalous points\n",
    "        if all(rind==rind0):\n",
    "            print('Convergence in {} iterations'.format(i+1))\n",
    "            break\n",
    "    return l < Lthres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAutoEncoder(input_dim,encoding_dim):\n",
    "    #define autoencoder architecture\n",
    "    autoencoder = Sequential()\n",
    "    autoencoder.add(Dense(encoding_dim[0], input_shape=(input_dim,), activation='relu'))\n",
    "\n",
    "    for l in range(1,len(encoding_dim)):\n",
    "        #autoencoder.add(Dropout(0.1))\n",
    "        autoencoder.add(Dense(encoding_dim[l], input_shape=(encoding_dim[l-1],), activation='relu'))\n",
    "    \n",
    "    for l in range(len(encoding_dim)-1,1,-1):\n",
    "        autoencoder.add(Dense(encoding_dim[l-1], input_shape=(encoding_dim[l],), activation='relu'))\n",
    "\n",
    "    autoencoder.add(Dense(input_dim, input_shape=(encoding_dim[0],), activation='sigmoid'))\n",
    "\n",
    "    autoencoder.summary()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract encoder layers from the networks\n",
    "def encoderLayers(autoencoder,input_,n_layer):\n",
    "    output_=input_\n",
    "    for l in range(n_layer):\n",
    "        output_=autoencoder.layers[l](output_)\n",
    "    return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import events data\n",
    "def getEvents(EventDataPath,city):\n",
    "    events_data =EventDataPath+city+'Events.csv'\n",
    "    df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "\n",
    "    # dataframe for events\n",
    "    df_finalEvents =  df_events[['Date', 'Type']]\n",
    "\n",
    "    # list events\n",
    "    lis_event = df_finalEvents['Type'].unique()\n",
    "    lis_event = list(lis_event)\n",
    "    return (lis_event,df_finalEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoEncoderMatrix(matrix):\n",
    "    # Set random seeds\n",
    "    np.random.seed(112)\n",
    "    set_random_seed(22)\n",
    "    input_dim = matrix.shape[1]\n",
    "    encoding_dim = [500,100,15]\n",
    "    autoencoder = getAutoEncoder(input_dim,encoding_dim)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    history = autoencoder.fit(matrix, matrix,\n",
    "                    epochs=80,\n",
    "                    batch_size=50,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder = Model(input_layer, (encoderLayers(autoencoder,input_layer,len(encoding_dim))))\n",
    "    reducedMatrix = encoder.predict(matrix)\n",
    "    return reducedMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 500)               1020500   \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 15)                1515      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2040)              206040    \n",
      "=================================================================\n",
      "Total params: 1,279,755\n",
      "Trainable params: 1,279,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6925\n",
      "Epoch 2/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.6871\n",
      "Epoch 3/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.5979\n",
      "Epoch 4/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4161\n",
      "Epoch 5/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.4043\n",
      "Epoch 6/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4030\n",
      "Epoch 7/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4026\n",
      "Epoch 8/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4024\n",
      "Epoch 9/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4020\n",
      "Epoch 10/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.4018\n",
      "Epoch 11/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4017\n",
      "Epoch 12/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.4014\n",
      "Epoch 13/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4013\n",
      "Epoch 14/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4011\n",
      "Epoch 15/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4008\n",
      "Epoch 16/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.4007\n",
      "Epoch 17/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4005\n",
      "Epoch 18/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.4003\n",
      "Epoch 19/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.4001\n",
      "Epoch 20/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3999\n",
      "Epoch 21/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3997\n",
      "Epoch 22/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3995\n",
      "Epoch 23/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3993\n",
      "Epoch 24/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3991\n",
      "Epoch 25/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3989\n",
      "Epoch 26/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3987\n",
      "Epoch 27/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3985\n",
      "Epoch 28/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3983\n",
      "Epoch 29/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3981\n",
      "Epoch 30/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3979\n",
      "Epoch 31/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3977\n",
      "Epoch 32/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3976\n",
      "Epoch 33/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3974\n",
      "Epoch 34/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3973\n",
      "Epoch 35/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3971\n",
      "Epoch 36/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3970\n",
      "Epoch 37/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3969\n",
      "Epoch 38/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3968\n",
      "Epoch 39/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3967\n",
      "Epoch 40/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3966\n",
      "Epoch 41/80\n",
      "725/725 [==============================] - 1s 1ms/step - loss: 0.3966\n",
      "Epoch 42/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3965\n",
      "Epoch 43/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3964\n",
      "Epoch 44/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3963\n",
      "Epoch 45/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3962\n",
      "Epoch 46/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3962\n",
      "Epoch 47/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3961\n",
      "Epoch 48/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3961\n",
      "Epoch 49/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3961\n",
      "Epoch 50/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3960\n",
      "Epoch 51/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3959\n",
      "Epoch 52/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3958\n",
      "Epoch 53/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3958\n",
      "Epoch 54/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3957\n",
      "Epoch 55/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3957\n",
      "Epoch 56/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3956\n",
      "Epoch 57/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3955\n",
      "Epoch 58/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3954\n",
      "Epoch 59/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3953\n",
      "Epoch 60/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3953\n",
      "Epoch 61/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3952\n",
      "Epoch 62/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3951\n",
      "Epoch 63/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3950\n",
      "Epoch 64/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3949\n",
      "Epoch 65/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3948\n",
      "Epoch 66/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3947\n",
      "Epoch 67/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3946\n",
      "Epoch 68/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3944\n",
      "Epoch 69/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3945\n",
      "Epoch 70/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3943\n",
      "Epoch 71/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3940\n",
      "Epoch 72/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3939\n",
      "Epoch 73/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3940\n",
      "Epoch 74/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3935\n",
      "Epoch 75/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3935\n",
      "Epoch 76/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3934\n",
      "Epoch 77/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3929\n",
      "Epoch 78/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3931\n",
      "Epoch 79/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3931\n",
      "Epoch 80/80\n",
      "725/725 [==============================] - 1s 2ms/step - loss: 0.3930\n",
      "Threshhold:  0.1\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.2\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.3\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Convergence in 8 iterations\n",
      "Threshhold:  0.4\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "Threshhold:  0.5\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.6\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Convergence in 8 iterations\n",
      "Threshhold:  0.7\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Threshhold:  0.8\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Convergence in 9 iterations\n",
      "Threshhold:  0.9\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "National Holiday\n",
      "0.4878048780487805 0.39473684210526316\n",
      "Protest\n",
      "0.56 0.3942857142857143\n",
      "Extreme Weather\n",
      "0.4634146341463415 0.3961988304093567\n",
      "Culture Event\n",
      "0.25 0.40425531914893614\n",
      "Taipei\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 500)               5832500   \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 15)                1515      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 11664)             1178064   \n",
      "=================================================================\n",
      "Total params: 7,063,779\n",
      "Trainable params: 7,063,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "638/638 [==============================] - 8s 12ms/step - loss: 0.6931\n",
      "Epoch 2/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6930\n",
      "Epoch 3/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6926\n",
      "Epoch 4/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6915\n",
      "Epoch 5/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6876\n",
      "Epoch 6/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6747\n",
      "Epoch 7/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6472\n",
      "Epoch 8/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6240\n",
      "Epoch 9/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6155\n",
      "Epoch 10/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6123\n",
      "Epoch 11/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6100\n",
      "Epoch 12/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6084\n",
      "Epoch 13/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6071\n",
      "Epoch 14/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6065\n",
      "Epoch 15/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6061\n",
      "Epoch 16/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6061\n",
      "Epoch 17/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6071\n",
      "Epoch 18/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6061\n",
      "Epoch 19/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6063\n",
      "Epoch 20/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6059\n",
      "Epoch 21/80\n",
      "638/638 [==============================] - 5s 8ms/step - loss: 0.6060\n",
      "Epoch 22/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6059\n",
      "Epoch 23/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6059\n",
      "Epoch 24/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6061\n",
      "Epoch 25/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6058\n",
      "Epoch 26/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6058\n",
      "Epoch 27/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6058\n",
      "Epoch 28/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6057\n",
      "Epoch 29/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6058\n",
      "Epoch 30/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6057\n",
      "Epoch 31/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6059\n",
      "Epoch 32/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6058\n",
      "Epoch 33/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6057\n",
      "Epoch 34/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6056\n",
      "Epoch 35/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6056\n",
      "Epoch 36/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6056\n",
      "Epoch 37/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6056\n",
      "Epoch 38/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6057\n",
      "Epoch 39/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6056\n",
      "Epoch 40/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6056\n",
      "Epoch 41/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6059\n",
      "Epoch 42/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6055\n",
      "Epoch 43/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6056\n",
      "Epoch 44/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6055\n",
      "Epoch 45/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6055\n",
      "Epoch 46/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6053\n",
      "Epoch 47/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6055\n",
      "Epoch 48/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6053\n",
      "Epoch 49/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6052\n",
      "Epoch 50/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6054\n",
      "Epoch 51/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6053\n",
      "Epoch 52/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6052\n",
      "Epoch 53/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6052\n",
      "Epoch 54/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6050\n",
      "Epoch 55/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6050\n",
      "Epoch 56/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6050\n",
      "Epoch 57/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6049\n",
      "Epoch 58/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6049\n",
      "Epoch 59/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6052\n",
      "Epoch 60/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6048\n",
      "Epoch 61/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6047\n",
      "Epoch 62/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6046\n",
      "Epoch 63/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6045\n",
      "Epoch 64/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6044\n",
      "Epoch 65/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6043\n",
      "Epoch 66/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6044\n",
      "Epoch 67/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6043\n",
      "Epoch 68/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6039\n",
      "Epoch 69/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6038\n",
      "Epoch 70/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6038\n",
      "Epoch 71/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6039\n",
      "Epoch 72/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6036\n",
      "Epoch 73/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6033\n",
      "Epoch 74/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6031\n",
      "Epoch 75/80\n",
      "638/638 [==============================] - 5s 8ms/step - loss: 0.6031\n",
      "Epoch 76/80\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.6029\n",
      "Epoch 77/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6027\n",
      "Epoch 78/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6027\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6028\n",
      "Epoch 80/80\n",
      "638/638 [==============================] - 4s 7ms/step - loss: 0.6021\n",
      "Threshhold:  0.1\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "Threshhold:  0.2\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.3\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Convergence in 9 iterations\n",
      "Threshhold:  0.4\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Threshhold:  0.5\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Convergence in 11 iterations\n",
      "Threshhold:  0.6\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Convergence in 13 iterations\n",
      "Threshhold:  0.7\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Threshhold:  0.8\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Threshhold:  0.9\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "National Holiday\n",
      "0.0 0.19905956112852666\n",
      "Natural Disaster\n",
      "0.8 0.1943127962085308\n",
      "Culture Event\n",
      "0.6666666666666666 0.1968503937007874\n",
      "Extreme Weather\n",
      "0.17543859649122806 0.20137693631669534\n",
      "Chicago\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 500)               502000    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 15)                1515      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1003)              101303    \n",
      "=================================================================\n",
      "Total params: 656,518\n",
      "Trainable params: 656,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "731/731 [==============================] - 3s 4ms/step - loss: 0.6910\n",
      "Epoch 2/80\n",
      "731/731 [==============================] - 1s 882us/step - loss: 0.6729\n",
      "Epoch 3/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.3978\n",
      "Epoch 4/80\n",
      "731/731 [==============================] - 1s 900us/step - loss: 0.2110\n",
      "Epoch 5/80\n",
      "731/731 [==============================] - 1s 785us/step - loss: 0.2042\n",
      "Epoch 6/80\n",
      "731/731 [==============================] - 1s 964us/step - loss: 0.2018\n",
      "Epoch 7/80\n",
      "731/731 [==============================] - 1s 784us/step - loss: 0.1995\n",
      "Epoch 8/80\n",
      "731/731 [==============================] - 1s 776us/step - loss: 0.1975\n",
      "Epoch 9/80\n",
      "731/731 [==============================] - 1s 819us/step - loss: 0.1955\n",
      "Epoch 10/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1939\n",
      "Epoch 11/80\n",
      "731/731 [==============================] - 1s 835us/step - loss: 0.1926\n",
      "Epoch 12/80\n",
      "731/731 [==============================] - 1s 853us/step - loss: 0.1916\n",
      "Epoch 13/80\n",
      "731/731 [==============================] - 1s 967us/step - loss: 0.1909\n",
      "Epoch 14/80\n",
      "731/731 [==============================] - 1s 796us/step - loss: 0.1903\n",
      "Epoch 15/80\n",
      "731/731 [==============================] - 1s 785us/step - loss: 0.1899\n",
      "Epoch 16/80\n",
      "731/731 [==============================] - 1s 970us/step - loss: 0.1896\n",
      "Epoch 17/80\n",
      "731/731 [==============================] - 1s 841us/step - loss: 0.1893\n",
      "Epoch 18/80\n",
      "731/731 [==============================] - 1s 830us/step - loss: 0.1890\n",
      "Epoch 19/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1888\n",
      "Epoch 20/80\n",
      "731/731 [==============================] - 1s 826us/step - loss: 0.1885\n",
      "Epoch 21/80\n",
      "731/731 [==============================] - 1s 815us/step - loss: 0.1883\n",
      "Epoch 22/80\n",
      "731/731 [==============================] - 1s 866us/step - loss: 0.1881\n",
      "Epoch 23/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1878\n",
      "Epoch 24/80\n",
      "731/731 [==============================] - 1s 817us/step - loss: 0.1875\n",
      "Epoch 25/80\n",
      "731/731 [==============================] - 1s 821us/step - loss: 0.1873\n",
      "Epoch 26/80\n",
      "731/731 [==============================] - 1s 979us/step - loss: 0.1870\n",
      "Epoch 27/80\n",
      "731/731 [==============================] - 1s 854us/step - loss: 0.1867\n",
      "Epoch 28/80\n",
      "731/731 [==============================] - 1s 832us/step - loss: 0.1864\n",
      "Epoch 29/80\n",
      "731/731 [==============================] - 1s 978us/step - loss: 0.1861\n",
      "Epoch 30/80\n",
      "731/731 [==============================] - 1s 898us/step - loss: 0.1859\n",
      "Epoch 31/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1855\n",
      "Epoch 32/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1851\n",
      "Epoch 33/80\n",
      "731/731 [==============================] - 1s 890us/step - loss: 0.1846\n",
      "Epoch 34/80\n",
      "731/731 [==============================] - 1s 934us/step - loss: 0.1841\n",
      "Epoch 35/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1835\n",
      "Epoch 36/80\n",
      "731/731 [==============================] - 1s 857us/step - loss: 0.1828\n",
      "Epoch 37/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1821\n",
      "Epoch 38/80\n",
      "731/731 [==============================] - 1s 940us/step - loss: 0.1815\n",
      "Epoch 39/80\n",
      "731/731 [==============================] - 1s 850us/step - loss: 0.1808\n",
      "Epoch 40/80\n",
      "731/731 [==============================] - 1s 822us/step - loss: 0.1802\n",
      "Epoch 41/80\n",
      "731/731 [==============================] - 1s 969us/step - loss: 0.1797\n",
      "Epoch 42/80\n",
      "731/731 [==============================] - 1s 834us/step - loss: 0.1793\n",
      "Epoch 43/80\n",
      "731/731 [==============================] - 1s 826us/step - loss: 0.1790\n",
      "Epoch 44/80\n",
      "731/731 [==============================] - 1s 973us/step - loss: 0.1787\n",
      "Epoch 45/80\n",
      "731/731 [==============================] - 1s 856us/step - loss: 0.1785\n",
      "Epoch 46/80\n",
      "731/731 [==============================] - 1s 814us/step - loss: 0.1782\n",
      "Epoch 47/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1781\n",
      "Epoch 48/80\n",
      "731/731 [==============================] - 1s 846us/step - loss: 0.1779\n",
      "Epoch 49/80\n",
      "731/731 [==============================] - 1s 841us/step - loss: 0.1777\n",
      "Epoch 50/80\n",
      "731/731 [==============================] - 1s 975us/step - loss: 0.1776\n",
      "Epoch 51/80\n",
      "731/731 [==============================] - 1s 853us/step - loss: 0.1775\n",
      "Epoch 52/80\n",
      "731/731 [==============================] - 1s 875us/step - loss: 0.1774\n",
      "Epoch 53/80\n",
      "731/731 [==============================] - 1s 999us/step - loss: 0.1773\n",
      "Epoch 54/80\n",
      "731/731 [==============================] - 1s 854us/step - loss: 0.1772\n",
      "Epoch 55/80\n",
      "731/731 [==============================] - 1s 841us/step - loss: 0.1770\n",
      "Epoch 56/80\n",
      "731/731 [==============================] - 1s 849us/step - loss: 0.1770\n",
      "Epoch 57/80\n",
      "731/731 [==============================] - 1s 983us/step - loss: 0.1769\n",
      "Epoch 58/80\n",
      "731/731 [==============================] - 1s 811us/step - loss: 0.1769\n",
      "Epoch 59/80\n",
      "731/731 [==============================] - 1s 828us/step - loss: 0.1768\n",
      "Epoch 60/80\n",
      "731/731 [==============================] - 1s 1ms/step - loss: 0.1767\n",
      "Epoch 61/80\n",
      "731/731 [==============================] - 1s 856us/step - loss: 0.1767\n",
      "Epoch 62/80\n",
      "731/731 [==============================] - 1s 844us/step - loss: 0.1766\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 1s 985us/step - loss: 0.1766\n",
      "Epoch 64/80\n",
      "731/731 [==============================] - 1s 794us/step - loss: 0.1766\n",
      "Epoch 65/80\n",
      "731/731 [==============================] - 1s 777us/step - loss: 0.1765\n",
      "Epoch 66/80\n",
      "731/731 [==============================] - 1s 984us/step - loss: 0.1764\n",
      "Epoch 67/80\n",
      "731/731 [==============================] - 1s 827us/step - loss: 0.1764\n",
      "Epoch 68/80\n",
      "731/731 [==============================] - 1s 805us/step - loss: 0.1764\n",
      "Epoch 69/80\n",
      "731/731 [==============================] - 1s 806us/step - loss: 0.1763\n",
      "Epoch 70/80\n",
      "731/731 [==============================] - 1s 967us/step - loss: 0.1763\n",
      "Epoch 71/80\n",
      "731/731 [==============================] - 1s 805us/step - loss: 0.1763\n",
      "Epoch 72/80\n",
      "731/731 [==============================] - 1s 808us/step - loss: 0.1762\n",
      "Epoch 73/80\n",
      "731/731 [==============================] - 1s 940us/step - loss: 0.1762\n",
      "Epoch 74/80\n",
      "731/731 [==============================] - 1s 812us/step - loss: 0.1761\n",
      "Epoch 75/80\n",
      "731/731 [==============================] - 1s 809us/step - loss: 0.1761\n",
      "Epoch 76/80\n",
      "731/731 [==============================] - 1s 976us/step - loss: 0.1761\n",
      "Epoch 77/80\n",
      "731/731 [==============================] - 1s 806us/step - loss: 0.1761\n",
      "Epoch 78/80\n",
      "731/731 [==============================] - 1s 809us/step - loss: 0.1760\n",
      "Epoch 79/80\n",
      "731/731 [==============================] - 1s 797us/step - loss: 0.1760\n",
      "Epoch 80/80\n",
      "731/731 [==============================] - 1s 970us/step - loss: 0.1759\n",
      "Threshhold:  0.1\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Convergence in 5 iterations\n",
      "Threshhold:  0.2\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Convergence in 5 iterations\n",
      "Threshhold:  0.3\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.4\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.5\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.6\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Convergence in 7 iterations\n",
      "Threshhold:  0.7\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "Threshhold:  0.8\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Convergence in 6 iterations\n",
      "Threshhold:  0.9\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Convergence in 5 iterations\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Convergence in 5 iterations\n",
      "National Holiday\n",
      "0.0 0.09986320109439124\n",
      "Culture Event\n",
      "0.0 0.10041265474552957\n",
      "Extreme Weather\n",
      "0.0851063829787234 0.10087719298245613\n",
      "NewYork\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 500)               32896500  \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 15)                1515      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               1600      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 65792)             6644992   \n",
      "=================================================================\n",
      "Total params: 39,594,707\n",
      "Trainable params: 39,594,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/80\n",
      "730/730 [==============================] - 33s 46ms/step - loss: 0.6931\n",
      "Epoch 2/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.6931\n",
      "Epoch 3/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.6929\n",
      "Epoch 4/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.6917\n",
      "Epoch 5/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.6771\n",
      "Epoch 6/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.5401\n",
      "Epoch 7/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4519\n",
      "Epoch 8/80\n",
      "730/730 [==============================] - 28s 38ms/step - loss: 0.4419\n",
      "Epoch 9/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4348\n",
      "Epoch 10/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4281\n",
      "Epoch 11/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4223\n",
      "Epoch 12/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4187\n",
      "Epoch 13/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4168\n",
      "Epoch 14/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4153\n",
      "Epoch 15/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4164\n",
      "Epoch 16/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4133\n",
      "Epoch 17/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4127\n",
      "Epoch 18/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4119\n",
      "Epoch 19/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4109\n",
      "Epoch 20/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4073\n",
      "Epoch 21/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.4028\n",
      "Epoch 22/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3980\n",
      "Epoch 23/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3896\n",
      "Epoch 24/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3849\n",
      "Epoch 25/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3810\n",
      "Epoch 26/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3795\n",
      "Epoch 27/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3786\n",
      "Epoch 28/80\n",
      "730/730 [==============================] - 28s 38ms/step - loss: 0.3796\n",
      "Epoch 29/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3774\n",
      "Epoch 30/80\n",
      "730/730 [==============================] - 29s 40ms/step - loss: 0.3787\n",
      "Epoch 31/80\n",
      "730/730 [==============================] - 29s 39ms/step - loss: 0.3767\n",
      "Epoch 32/80\n",
      "730/730 [==============================] - 27s 38ms/step - loss: 0.3779\n",
      "Epoch 33/80\n",
      "730/730 [==============================] - 30s 40ms/step - loss: 0.3768\n",
      "Epoch 34/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3764\n",
      "Epoch 35/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3780\n",
      "Epoch 36/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3773\n",
      "Epoch 37/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3759\n",
      "Epoch 38/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3761\n",
      "Epoch 39/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3771\n",
      "Epoch 40/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3762\n",
      "Epoch 41/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3768\n",
      "Epoch 42/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3761\n",
      "Epoch 43/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3774\n",
      "Epoch 44/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3761\n",
      "Epoch 45/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3755\n",
      "Epoch 46/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3765\n",
      "Epoch 47/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3762\n",
      "Epoch 48/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3758\n",
      "Epoch 49/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3761\n",
      "Epoch 50/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3759\n",
      "Epoch 51/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3754\n",
      "Epoch 52/80\n",
      "730/730 [==============================] - 36s 49ms/step - loss: 0.3751\n",
      "Epoch 53/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730/730 [==============================] - 34s 47ms/step - loss: 0.3756\n",
      "Epoch 54/80\n",
      "730/730 [==============================] - 32s 43ms/step - loss: 0.3756\n",
      "Epoch 55/80\n",
      "730/730 [==============================] - 30s 41ms/step - loss: 0.3755\n",
      "Epoch 56/80\n",
      "730/730 [==============================] - 31s 42ms/step - loss: 0.3760\n",
      "Epoch 57/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3759\n",
      "Epoch 58/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3750\n",
      "Epoch 59/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3751\n",
      "Epoch 60/80\n",
      "730/730 [==============================] - 27s 38ms/step - loss: 0.3764\n",
      "Epoch 61/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3753\n",
      "Epoch 62/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3748\n",
      "Epoch 63/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3750\n",
      "Epoch 64/80\n",
      "730/730 [==============================] - 30s 41ms/step - loss: 0.3768\n",
      "Epoch 65/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3750\n",
      "Epoch 66/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3749\n",
      "Epoch 67/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3750\n",
      "Epoch 68/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3750\n",
      "Epoch 69/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3756\n",
      "Epoch 70/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3757\n",
      "Epoch 71/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3753\n",
      "Epoch 72/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3751\n",
      "Epoch 73/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3752\n",
      "Epoch 74/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3747\n",
      "Epoch 75/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3755\n",
      "Epoch 76/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3748\n",
      "Epoch 77/80\n",
      "730/730 [==============================] - 27s 36ms/step - loss: 0.3747\n",
      "Epoch 78/80\n",
      "730/730 [==============================] - 27s 37ms/step - loss: 0.3752\n",
      "Epoch 79/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3752\n",
      "Epoch 80/80\n",
      "730/730 [==============================] - 26s 36ms/step - loss: 0.3755\n",
      "Threshhold:  0.1\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "Threshhold:  0.2\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Convergence in 12 iterations\n",
      "Threshhold:  0.3\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Threshhold:  0.4\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Convergence in 8 iterations\n",
      "Threshhold:  0.5\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Convergence in 9 iterations\n",
      "Threshhold:  0.6\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Threshhold:  0.7\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Convergence in 9 iterations\n",
      "Threshhold:  0.8\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Convergence in 11 iterations\n",
      "Threshhold:  0.9\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Convergence in 10 iterations\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Convergence in 4 iterations\n",
      "National Holiday\n",
      "0.0 0.1\n",
      "Culture Event\n",
      "0.11764705882352941 0.09957924263674614\n",
      "Extreme Weather\n",
      "0.10638297872340426 0.09956076134699854\n"
     ]
    }
   ],
   "source": [
    "f = open(RecordWritingPath+'F1ScoreAutoEncoder.txt', 'w+')\n",
    "f.write('Auto Encoder\\n')\n",
    "for city in ['DC','Taipei','Chicago','NewYork']:\n",
    "    print(city)\n",
    "    f.write(city+'\\n')\n",
    "    data = readTransDF(TransportationDataPath,city)\n",
    "    lis_event,df_finalEvents = getEvents(EventDataPath,city)\n",
    "    dataTs = getTimeSeries(data)\n",
    "    matrix = dataTs.values\n",
    "    matrix = np.log(matrix+1)\n",
    "    for i in range(matrix.shape[1]):\n",
    "        matrix[:, i] = (matrix[:, i] - matrix[:, i].min()) / (matrix[:, i].max() - matrix[:, i].min())\n",
    "    matrix = AutoEncoderMatrix(matrix)\n",
    "    date = dataTs.index.to_frame().rename(columns={'date':'Date'})\n",
    "    result = {}\n",
    "    for thres in range(1,10, 1):\n",
    "        th = thres/10\n",
    "        print(\"Threshhold: \",th)\n",
    "        outliers = anomalyDetection(matrix,pval = th)\n",
    "        EventsDF = df_finalEvents['Date'].drop_duplicates().to_frame()\n",
    "        EventsDF['Anomaly'] = True\n",
    "        date['Date'] = date['Date'].astype('str')\n",
    "        EventsDF['Date'] = EventsDF['Date'].astype('str')\n",
    "        df = EventsDF.merge(date,on='Date',how='right')\n",
    "        df['outlier'] = outliers\n",
    "        Precision = len(df[(df['outlier']==True)&(df['Anomaly']==True)])/len(df[df['outlier']==True])\n",
    "        Recall = len(df[(df['outlier']==True)&(df['Anomaly']==True)])/len(EventsDF)\n",
    "        if Precision+Recall > 0:\n",
    "            F1 = (2*Precision*Recall)/(Precision+Recall)\n",
    "        else:\n",
    "            F1 = 0\n",
    "        result[th] = F1\n",
    "    bestTh = max(result.items(), key=operator.itemgetter(1))[0]\n",
    "    f.write('overall F1: '+str(result[bestTh])+', Threshold: '+str(bestTh)+'\\n')\n",
    "    f.write('event,single_type_recall,single_type_FPR\\n')\n",
    "    EventType = list(df_finalEvents['Type'].unique())\n",
    "    outliers = anomalyDetection(matrix,pval = bestTh)\n",
    "    for event in EventType:\n",
    "        print(event)\n",
    "        SingleEventDF = df_finalEvents[df_finalEvents['Type'] == event]\n",
    "        SingleEventDF = SingleEventDF.drop_duplicates()\n",
    "        date['Date'] = date['Date'].astype('str')\n",
    "        SingleEventDF['Date'] = SingleDF['Date'].astype('str')\n",
    "        SingleDF = date.merge(SingleEventDF, on='Date', how='left')\n",
    "    #     SingleDF = SingleEventDF.merge(date,on='Date',how='left')\n",
    "        SingleDF['outliers'] = outliers\n",
    "    #     SinglePrecision = len(SingleDF[(SingleDF['outlier']==True)&(SingleDF['Type'].notnull)])/len(SingleDF[SingleDF['outlier']==True])\n",
    "        SingleRecall = len(SingleDF[(SingleDF['outliers']==True)&(SingleDF['Type'].notnull())])/len(SingleEventDF)\n",
    "        SingleFPR = len(SingleDF[(SingleDF['outliers']==True)&(SingleDF['Type'].isna())])/len(SingleDF[SingleDF['Type'].isna()])\n",
    "        print(SingleRecall, SingleFPR)\n",
    "        f.write(event+','+str(SingleRecall)+','+str(SingleFPR)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
