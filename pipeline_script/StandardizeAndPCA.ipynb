{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add necessary libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.decomposition import PCA\n",
    "import datetime\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordWritingPath = '/Users/hemingyi/Documents/capstone/post/result/'\n",
    "TransportationDataPath = '/Users/hemingyi/Documents/capstone/post/transportation/'\n",
    "EventDataPath = '/Users/hemingyi/Documents/capstone/post/events/'\n",
    "comboPath = '/Users/hemingyi/Documents/capstone/combo/'\n",
    "PostData = '/Users/hemingyi/Documents/capstone/post/'\n",
    "# dataFile = TransportationDataPath+city+'EdgeYearwiseAggregated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='amount', index=['date'],\n",
    "                    columns=['start_id','end_id'], aggfunc=np.sum, fill_value=0).sort_index()\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(city, raw, DimensionReduction):\n",
    "    if raw == 'Comm':\n",
    "        data = pd.read_csv(TransportationDataPath+'SubComm/'+city+'DateWiseSubComm.csv')\n",
    "        data = getTimeSeries(data)\n",
    "        data = data.sort_index()\n",
    "        \n",
    "        matrix = data.values\n",
    "    elif raw == 'IO':\n",
    "        data = pd.read_csv(TransportationDataPath+city+'InOutFlow.csv', date_parser='date')\n",
    "        data = data.sort_values(['date'])\n",
    "        data.index = data.date\n",
    "        del data['date']\n",
    "        matrix = data.values\n",
    "    \n",
    "    matrix = np.log(matrix+1)\n",
    "    \n",
    "#     norm column\n",
    "    for i in range(matrix.shape[1]):\n",
    "        matrix[:, i] = (matrix[:, i] - matrix[:, i].min()) / (matrix[:, i].max() - matrix[:, i].min())\n",
    "    if DimensionReduction is True:\n",
    "        pca = PCA(n_components=16)    \n",
    "        matrix=pca.fit_transform(matrix)\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/PCA/Normalize/'+city+raw+'Normalize.csv',index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/OriginSize/Normalize/'+city+raw+'Normalize.csv',index=False)\n",
    "\n",
    "#     norm row\n",
    "    for i in range(matrix.shape[0]):\n",
    "        matrix[i, :] = (matrix[i, :] - matrix[i, :].min()) / (matrix[i, :].max() - matrix[i, :].min())\n",
    "    if DimensionReduction is True:\n",
    "        pca = PCA(n_components=16)    \n",
    "        matrix=pca.fit_transform(matrix)\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/PCA/Whiten/'+city+raw+'Whiten.csv',index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/OriginSize/Whiten/'+city+raw+'Whiten.csv',index=False)\n",
    "\n",
    "    matrix = (matrix - matrix.min()) / (matrix.max() - matrix.min())\n",
    "    if DimensionReduction is True:\n",
    "        pca = PCA(n_components=16)    \n",
    "        matrix=pca.fit_transform(matrix)\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/PCA/Both/'+city+raw+'Both.csv',index=False)\n",
    "    else:\n",
    "        df = pd.DataFrame(matrix)\n",
    "        df['date'] = data.index\n",
    "        df.to_csv(TransportationDataPath+'Output/'+raw+'/OriginSize/Both/'+city+raw+'Both.csv',index=False)\n",
    "    print(city,raw,'PCA',DimensionReduction,'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago\n",
      "Chicago Comm PCA False done\n",
      "Chicago Comm PCA True done\n",
      "Chicago IO PCA False done\n",
      "Chicago IO PCA True done\n",
      "NewYork\n",
      "NewYork Comm PCA False done\n",
      "NewYork Comm PCA True done\n",
      "NewYork IO PCA False done\n",
      "NewYork IO PCA True done\n",
      "DC\n",
      "DC Comm PCA False done\n",
      "DC Comm PCA True done\n",
      "DC IO PCA False done\n",
      "DC IO PCA True done\n",
      "Taipei\n",
      "Taipei Comm PCA False done\n",
      "Taipei Comm PCA True done\n",
      "Taipei IO PCA False done\n",
      "Taipei IO PCA True done\n"
     ]
    }
   ],
   "source": [
    "for city in ['Chicago','NewYork','DC','Taipei']:\n",
    "    print(city)\n",
    "    standardize(city, 'Comm', DimensionReduction=False)\n",
    "    standardize(city, 'Comm', DimensionReduction=True)\n",
    "    standardize(city, 'IO', DimensionReduction=False)\n",
    "    standardize(city, 'IO', DimensionReduction=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
