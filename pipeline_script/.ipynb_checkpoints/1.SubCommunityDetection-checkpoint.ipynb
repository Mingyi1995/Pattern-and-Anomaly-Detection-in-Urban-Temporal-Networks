{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add necessary libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture \n",
    "import datetime\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordWritingPath = '../result/'\n",
    "TransportationDataPath = '../transportation/'\n",
    "EventDataPath = '../events/'\n",
    "comboPath = '../combo/'\n",
    "PostData = '/Users/hemingyi/Documents/capstone/post/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(TransportationDataPath+'/Comm') == False:\n",
    "    os.makedirs(TransportationDataPath+'/Comm')\n",
    "if os.path.exists(comboPath+'/temp')== False:\n",
    "    os.makedirs(comboPath+'/temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTransDF(TransportationDataPath,city):\n",
    "    df = pd.read_csv(TransportationDataPath+city+'EdgeYearwiseAggregated.csv')\n",
    "    return df\n",
    "def makeGraphfromDf(df):\n",
    "    G=nx.DiGraph()\n",
    "    nx.set_edge_attributes(G,'weight', 0)\n",
    "    for k in df.index:\n",
    "        G.add_edge(df['start_id'][k],df['end_id'][k],weight=df['amount'][k])\n",
    "#     nx.write_edgelist(G, comboPath+'temp/%s.net'%city)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComboPartition(G,comboPath,city):\n",
    "    #save network in net format\n",
    "    nodenum={}\n",
    "#     G = makeGraphfromDf(df)\n",
    "    #create a dictionary transforming nodes to unique numbers\n",
    "    nodes = list(G.nodes())\n",
    "#     print('nodes amount: ',len(nodes))\n",
    "    for i,j in enumerate(list(G.nodes())):\n",
    "        nodenum[str(j)] = str(i)\n",
    "#         nodes[str(i)] = str(j)\n",
    "#     i=0\n",
    "#     for n in list(G.nodes()):\n",
    "#         nodenum[n]=i\n",
    "#         nodes[i]=n\n",
    "#         i+=1\n",
    "    \n",
    "    tempNetFile = comboPath+'temp/%s.net'%city\n",
    "#     print(tempNetFile)\n",
    "    f = open(tempNetFile, 'w')\n",
    "    f.write('*Arcs\\n')\n",
    "\n",
    "    for e in G.edges(data=True):\n",
    "        f.write('{0} {1} {2}\\n'.format(nodenum[str(e[0])],nodenum[str(e[1])],e[2]['weight']))\n",
    "    f.close()\n",
    "\n",
    "    #run combo\n",
    "    command= comboPath+'/comboCPP '+tempNetFile#+' '+str(maxcom)\n",
    "    os.system(command)\n",
    "\n",
    "    #read resulting partition\n",
    "    partitionFile = comboPath+'temp/'+city + '_comm_comboC++.txt'\n",
    "    f = open(partitionFile, 'r')\n",
    "    i=0\n",
    "    partition={}\n",
    "    for line in f:\n",
    "        partition[str(nodes[i])]=str(int(line))\n",
    "        i+=1\n",
    "#         print(i)\n",
    "    f.close()\n",
    "    os.remove(partitionFile) \n",
    "    os.remove(tempNetFile)\n",
    "#     print(\"Communities: \",len(set(partition.values())))\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubCommunity(df,city,maxComm=None):\n",
    "    data2 = df[df.start_community == df.end_community]\n",
    "    communities = list(set(df.start_community))\n",
    "#     print('communities numbers: ',len(communities))\n",
    "    SubPartition = {}\n",
    "    for c in communities:\n",
    "#         print('detecting sub-communities in community ',c)\n",
    "        d = data2[data2.start_community == c]\n",
    "        graph = makeGraphfromDf(d)\n",
    "        p = getComboPartition(graph,comboPath,city)\n",
    "        SubPartition[c] = p\n",
    "    df['start_community'] = df.apply(lambda x: str(x['start_community'])+'.'+str(SubPartition[x['start_community']][str(x['start_id'])]),axis=1)\n",
    "    df['end_community'] = df.apply(lambda x: str(x['end_community'])+'.'+str(SubPartition[x['end_community']][str(x['end_id'])]),axis=1)\n",
    "    communityNum = len(df['start_community'].unique())\n",
    "#     print('communityNum: ', communityNum)\n",
    "    if maxComm:\n",
    "        if communityNum >= maxComm:\n",
    "            return df\n",
    "        else:\n",
    "#             print('Continue commuity detection')\n",
    "            return(getSubCommunity(df,city))\n",
    "    else:\n",
    "        if communityNum >= 10:\n",
    "            return df\n",
    "        else:\n",
    "#             print('Continue commuity detection')\n",
    "            return(getSubCommunity(df,city))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateByCommunities(commdata,city,TransportationDataPath):\n",
    "    commdata = pd.melt(commdata, id_vars=['start_id'], value_vars=['start_community']).drop_duplicates()[['start_id','value']]\n",
    "    data = pd.read_csv(TransportationDataPath+city+'EdgeDatewiseAggregated.csv')\n",
    "\n",
    "    print('Raw shape: ',data.shape)\n",
    "    if 'Date' in data.columns:\n",
    "        data['date'] = pd.to_datetime(data.Date)\n",
    "    elif 'date' in data.columns:\n",
    "        data['date'] = pd.to_datetime(data.date)\n",
    "    else:\n",
    "        print(data.columns)\n",
    "    data = data.merge(commdata, right_on='start_id', left_on='start_id')\n",
    "    data = data.merge(commdata, left_on='end_id',right_on='start_id' )\n",
    "    \n",
    "    communityData = data[['value_x','value_y','date','amount']]\n",
    "    communityData = communityData.groupby(['value_x','value_y','date']).sum().reset_index()\n",
    "    communityData.columns = ['start_id', 'end_id', 'date', 'amount']\n",
    "\n",
    "    return communityData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get sub comm for NYC\n",
    "def subComm(city,maxComm=None):\n",
    "#     f = open(RecordWritingPath+'F1ScoreSubCommunity.txt', 'a+')\n",
    "    print('Initialize')\n",
    "    df = readTransDF(TransportationDataPath,city)\n",
    "    print('Community Detection, aim at max', maxComm,' communities')\n",
    "    G = makeGraphfromDf(df)\n",
    "#     print(city)\n",
    "    partition = getComboPartition(G,comboPath,city)\n",
    "    df['start_community'] = df['start_id'].apply(lambda x: partition[str(x)])\n",
    "    df['end_community'] = df['end_id'].apply(lambda x: partition[str(x)])\n",
    "    Commdata = getSubCommunity(df,city,maxComm)\n",
    "    print('aggregate date wise data by communities')\n",
    "    data = aggregateByCommunities(Commdata,city,TransportationDataPath)\n",
    "    print('Save Aggregated DF to csv')\n",
    "    data.to_csv(TransportationDataPath+'Comm/'+city+'DateWiseComm.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize\n",
      "Community Detection, aim at max None  communities\n",
      "aggregate date wise data by communities\n",
      "Raw shape:  (7374816, 4)\n",
      "Save Aggregated DF to csv\n"
     ]
    }
   ],
   "source": [
    "subComm('Taipei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize\n",
      "Community Detection, aim at max None  communities\n",
      "aggregate date wise data by communities\n",
      "Raw shape:  (19415921, 4)\n"
     ]
    }
   ],
   "source": [
    "subComm('NewYork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
