{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add necessary libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.decomposition import PCA\n",
    "import datetime\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordWritingPath = '/Users/hemingyi/Documents/capstone/code/result/web/'\n",
    "TransportationDataPath = '/Users/hemingyi/Documents/capstone/transportation/'\n",
    "EventDataPath = '/Users/hemingyi/Documents/capstone/event data/update/'\n",
    "comboPath = '/Users/hemingyi/Documents/capstone/combo/'\n",
    "WebData = '/Users/hemingyi/Documents/capstone/webdata/'\n",
    "# dataFile = TransportationDataPath+city+'EdgeYearwiseAggregated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyDetection(y,ncom,pval = 0.2,iterN=20):\n",
    "    #index of regular (non-outlier points)\n",
    "\n",
    "    rind = np.array(range(y.shape[0]))\n",
    "    \n",
    "    #clustering model\n",
    "    gm=GaussianMixture(n_components=ncom,n_init=100,max_iter=1000,random_state=0) \n",
    "    for i in range(iterN): #iterate\n",
    "#         print('Iteration {}'.format(i+1))  \n",
    "        clustering=gm.fit(y[rind,:]) #fit EM clustering model excluding outliers\n",
    "        l=clustering.score_samples(y) #estimate likelihood for each point\n",
    "        Lthres=sorted(l)[int(len(l)*pval)] #anomaly threshold\n",
    "#         print(Lthres)\n",
    "        rind0=0+rind\n",
    "        rind=l>Lthres #non-anomalous points\n",
    "        if all(rind==rind0):\n",
    "#             print('Convergence in {} iterations'.format(i+1))\n",
    "            break\n",
    "    return l < Lthres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import events data\n",
    "def getEvents(EventDataPath,city):\n",
    "    events_data =EventDataPath+city+'Events.csv'\n",
    "    df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "\n",
    "    # dataframe for events\n",
    "    df_finalEvents =  df_events[['Date', 'Type']]\n",
    "\n",
    "    # list events666\n",
    "    \n",
    "    lis_event = df_finalEvents['Type'].unique()\n",
    "    lis_event = list(lis_event)\n",
    "    return (lis_event,df_finalEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(df):\n",
    "    table = pd.pivot_table(df, values='amount', index=['date'],\n",
    "                    columns=['start_id','end_id'], aggfunc=np.sum, fill_value=0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyDetection(y,ncomp,pval = 0.2,iterN=20):\n",
    "    #index of regular (non-outlier points)\n",
    "    #rind=y[:,0]>-10 \n",
    "    rind = np.array(range(y.shape[0]))\n",
    "    \n",
    "    #clustering model\n",
    "    gm=GaussianMixture(n_components=ncomp,n_init=100,max_iter=1000,random_state=0) \n",
    "    for i in range(iterN): #iterate\n",
    "#         print('Iteration {}'.format(i+1))  \n",
    "        clustering=gm.fit(y[rind,:]) #fit EM clustering model excluding outliers\n",
    "        l=clustering.score_samples(y) #estimate likelihood for each point\n",
    "        Lthres=sorted(l)[int(len(l)*pval)] #anomaly threshold\n",
    "        rind0=0+rind\n",
    "        rind=l>Lthres #non-anomalous points\n",
    "        if all(rind==rind0):\n",
    "#             print('Convergence in {} iterations'.format(i+1))\n",
    "            break\n",
    "    return l < Lthres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCommdata(city,TransportationDataPath):\n",
    "    data = pd.read_csv(TransportationDataPath+'Comm/'+city+'DateWiseComm.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lis_event,df_finalEvents = getEvents(EventDataPath,city)\n",
    "data = readCommdata(city,TransportationDataPath)\n",
    "\n",
    "dataTs = getTimeSeries(data)\n",
    "dataTs = dataTs.sort_index()\n",
    "matrix = dataTs.values\n",
    "matrix = np.log(matrix+1)\n",
    "for i in range(matrix.shape[1]):\n",
    "    matrix[:, i] = (matrix[:, i] - matrix[:, i].min()) / (matrix[:, i].max() - matrix[:, i].min())\n",
    "pca = PCA(n_components=16)\n",
    "matrix=pca.fit_transform(matrix)\n",
    "date = dataTs.index.to_frame().rename(columns={'date':'Date'})\n",
    "threresult = {}\n",
    "EventsDF = df_finalEvents.drop_duplicates(subset='Date', keep='first', inplace=False)\n",
    "EventsDF['Anomaly'] = True\n",
    "EventsDF['Date'] = EventsDF['Date'].astype('str')\n",
    "date['Date'] = date['Date'].astype('str')\n",
    "df = date.merge(EventsDF,on='Date',how='left')\n",
    "df.Anomaly.fillna(False, inplace=True)\n",
    "columns = []\n",
    "for i in range(1,17):\n",
    "    columns += ['Component%s'%i]\n",
    "outputMatrix = pd.DataFrame(data = matrix, index=df.Date.tolist(), columns=columns)\n",
    "outputMatrix.to_csv(WebData+city+'PCA.csv')\n",
    "print('saved pca matrix')\n",
    "for comp in [1,2,3,4,5]:\n",
    "    print('n_component',comp)\n",
    "    for thres in list(range(1,10,1))+[10*len(df[df['Anomaly']==True])/len(df)]:\n",
    "        th = thres/10\n",
    "        outliers = anomalyDetection(matrix,comp,pval = th)\n",
    "        df['outlier'] = outliers\n",
    "        TP = len(df[(df['outlier']==True)&(df['Anomaly']==True)])\n",
    "        FP = len(df[(df['outlier']==True)&(df['Anomaly']==False)])\n",
    "        TN = len(df[(df['outlier']==False)&(df['Anomaly']==False)])\n",
    "        FN = len(df[(df['outlier']==False)&(df['Anomaly']==True)])\n",
    "        f.write(city+',Comm + PCA + GMM,'+str(comp)+','+str(th)+','+str(TP)+','+str(FP)+','+str(TN)+','+str(FN)+',')\n",
    "        for event in ['National Holiday', 'Culture Event', 'Extreme Weather']:\n",
    "#             print(event)\n",
    "            T = len(df[df['Type']==event])\n",
    "            TP = len(df[(df['Type']==event)&(df['outlier']==True)])\n",
    "            TPR = TP/T\n",
    "            f.write(str(TPR)+',')\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
