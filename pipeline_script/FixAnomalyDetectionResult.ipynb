{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecordWritingPath = '/Users/hemingyi/Documents/capstone/post/result/'\n",
    "EventDataPath = '/Users/hemingyi/Documents/capstone/post/events/'\n",
    "datefile = '1008/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix wrong extreme weather data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEvents(EventDataPath,city):\n",
    "    events_data =EventDataPath+city+'Events.csv'\n",
    "    df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "\n",
    "    # dataframe for events\n",
    "    df_finalEvents =  df_events[['Date', 'Type']]\n",
    "    \n",
    "    df_finalEvents['National Holiday'] = False\n",
    "    df_finalEvents['Extreme Weather'] = False\n",
    "    df_finalEvents['Culture Event'] = False\n",
    "    df_finalEvents.loc[df_finalEvents['Type'] == 'National Holiday', 'National Holiday'] = True\n",
    "    df_finalEvents.loc[df_finalEvents['Type'] == 'Extreme Weather', 'Extreme Weather'] = True\n",
    "    df_finalEvents.loc[df_finalEvents['Type'] == 'Culture Event', 'Culture Event'] = True\n",
    "\n",
    "    df_finalEvents = df_finalEvents.groupby(['Date']).sum()\n",
    "    df_finalEvents['Anomaly'] = True\n",
    "    df_finalEvents.reset_index(inplace=True)\n",
    "    \n",
    "    return df_finalEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['Taipei', 'NewYork']:\n",
    "    df = pd.read_csv(RecordWritingPath+datefile+city+'Timeseries.csv')\n",
    "#     del df['Culture Event']\n",
    "    date = df[['Date']]\n",
    "    eventsdf = getEvents(EventDataPath, city)\n",
    "    eventsdf.Date = eventsdf.Date.astype('str')\n",
    "    eventsdf = date.merge(eventsdf,on='Date',how='outer')\n",
    "    df['Extreme Weather'] = eventsdf['Extreme Weather']\n",
    "    df['National Holiday'] = eventsdf['National Holiday']\n",
    "    df['Culture Event'] = eventsdf['Culture Event']\n",
    "    df['Anomaly'] = eventsdf['Anomaly']\n",
    "    df[list(df.columns)] = df[list(df.columns)].astype('str')\n",
    "    df = df.replace(['3.0','2.0','1.0','0.0','nan'],[True,True,True,False,False])\n",
    "    df = df.replace([3,2,1,0],[True,True,True,False])\n",
    "    df = df.fillna(False)\n",
    "#     del df['Culture Event']\n",
    "    df.to_csv(RecordWritingPath+datefile+city+'Timeseries.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, 'False', 'True'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Culture Event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NewYork-IO-OriginSize-Normalizeze"
     ]
    }
   ],
   "source": [
    "for aggregation in ['Comm', 'IO']:\n",
    "    for dimension in ['PCA', 'AE', 'OriginSize']:\n",
    "        for city in ['Taipei', 'NewYork']:\n",
    "            for standardize in ['Normalize']:#, 'Whiten', 'Both']:\n",
    "                print(\"\\r\",'%s-%s-%s-%s'%(city, aggregation, dimension, standardize),end='',flush=True)\n",
    "                df = pd.read_csv(RecordWritingPath+datefile+city+aggregation+dimension+standardize+'.csv')\n",
    "#                 del df['Culture Event']\n",
    "                date = df[['Date']]\n",
    "                eventsdf = getEvents(EventDataPath, city)\n",
    "                eventsdf.Date = eventsdf.Date.astype('str')\n",
    "                eventsdf = date.merge(eventsdf,on='Date',how='outer')\n",
    "                df['Extreme Weather'] = eventsdf['Extreme Weather']\n",
    "                df['National Holiday'] = eventsdf['National Holiday']\n",
    "                df['Culture Event'] = eventsdf['Culture Event']\n",
    "                df['Anomaly'] = eventsdf['Anomaly']\n",
    "                df = df.replace(['3.0','2.0','1.0','0.0','nan'],[True,True,True,False,False])\n",
    "                df = df.replace([3,2,1,0],[True,True,True,False])\n",
    "                df = df.fillna(False)\n",
    "#                     df[list(df.columns)] = df[list(df.columns)].astype('str')\n",
    "                \n",
    "                df.to_csv(RecordWritingPath+datefile+city+aggregation+dimension+standardize+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "National Holiday    19\n",
       "Culture Event        5\n",
       "Extreme Weather      3\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = \"DC\"\n",
    "events_data =EventDataPath+city+'Events.csv'\n",
    "df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "df_events.Type.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "National Holiday    16\n",
       "Extreme Weather      3\n",
       "Culture Event        3\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = \"NewYork\"\n",
    "events_data =EventDataPath+city+'Events.csv'\n",
    "df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "df_events.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "National Holiday    26\n",
       "Culture Event        4\n",
       "Extreme Weather      3\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = \"Taipei\"\n",
    "events_data =EventDataPath+city+'Events.csv'\n",
    "df_events = pd.read_csv(events_data, encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True)\n",
    "df_events.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hemingyi/Documents/capstone/post/result/1003/DCIOOriginSizeNormalize.csv'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecordWritingPath+datefile+city+aggregation+dimension+standardize+'.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
